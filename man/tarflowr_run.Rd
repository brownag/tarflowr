% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tarflowr.R
\name{tarflowr_run}
\alias{tarflowr_run}
\title{Run a parallelized, reproducible workflow using targets.}
\usage{
tarflowr_run(
  work_units,
  process_func,
  combine_func = NULL,
  project_dir,
  result_target_name = NULL,
  packages = c(),
  metadata = list(),
  workers = 1L,
  crew_controller = NULL,
  seed = NULL,
  error = "stop",
  force = FALSE,
  callr_function = callr::r,
  callr_arguments = list(stdout = "|", stderr = "2>&1")
)
}
\arguments{
\item{work_units}{list or vector. Each element represents a single unit of
work to be processed.}

\item{process_func}{function. Takes one element of \code{work_units} as its first
argument and returns the "processed" result.}

\item{combine_func}{function. Takes a list of all processed results from
\code{process_func} and combines them into a single, final object. If \code{NULL},
the final result will be the list of all processed results.}

\item{project_dir}{character. Path to the directory where the tarflowr
project will be created. It will be created if it does not exist.}

\item{result_target_name}{character. Name of the last target in the pipeline,
which contains the result of evaluating \code{combine_func} on the list of work
units. If \code{NULL} (default) the final target name is based on the project
directory name, with the suffix \code{"_result"}.}

\item{packages}{character. Vector of R package names that are required by the
\code{process_func} and \code{combine_func}. These will be passed as the option
\code{packages} to \code{\link[targets:tar_option_set]{targets::tar_option_set()}} to be loaded on each worker.}

\item{metadata}{list. Named list of elements to write to
\verb{_tarflowr_meta.yaml} file on successful run.}

\item{workers}{integer. Number of local parallel workers to use via the
\code{crew} package. This is only used when the default \code{crew_controller} is
\code{NULL}.}

\item{crew_controller}{crew_class_controller. Custom \code{crew} controller.
Default \code{NULL} uses \code{\link[crew:crew_controller_local]{crew::crew_controller_local()}} with the specified
number of \code{workers} (parallel processes). \code{\link[targets:tar_make]{targets::tar_make()}} is called
with the R option \verb{"targets.controller} set.}

\item{seed}{integer. Random number seed. Passed to
\code{\link[targets:tar_option_set]{targets::tar_option_set()}} via argument \code{seed}.}

\item{error}{character. Error behavior. Either \code{"stop"} (default) or
\code{"continue"}. Passed to \code{\link[targets:tar_option_set]{targets::tar_option_set()}} via argument \code{error}.}

\item{force}{logical. If \code{FALSE} (default), the hash of the input arguments
will be checked to determine if the work units or _targets.R file are
updated. If \code{TRUE} new work units and targets scripts will be written.}

\item{callr_function}{function. Passed to \code{\link[targets:tar_make]{targets::tar_make()}}. Default
\code{\link[callr:r]{callr::r()}} uses a new R session. Use \code{\link[callr:r_bg]{callr::r_bg()}} to run in background
and suppress targets pipeline output.}

\item{callr_arguments}{list. Arguments passed to \code{\link[targets:tar_make]{targets::tar_make()}}.}
}
\value{
The final combined result of the workflow, as returned by
\code{combine_func}, or the list of all processed results when \code{combine_func} is
\code{NULL}.
}
\description{
This function serves as a high-level interface to the 'targets' and 'crew'
packages. It programmatically generates a \verb{_targets.R} pipeline file based on
user-provided inputs, runs the pipeline, and returns the final result. It is
designed to abstract the complexity of setting up a 'targets'-based workflow
for common "map-reduce" or "split-apply-combine" tasks.
}
\details{
The function works by creating a self-contained project in the
\code{project_dir}. It serializes the user's \code{work_units} and functions
(\code{process_func}, \code{combine_func}) into this directory. It then generates a
\verb{_targets.R} script that orchestrates the following steps:
\enumerate{
\item Load the \code{work_units}
\item Map the \code{process_func} over each element of the \code{work_units} using
specified crew controller
\item Combine the results of the processing step using \code{combine_func}
(optional)
\item Execute the pipeline with \code{targets::tar_make()}
\item Load the final result into original R session
}
}
\examples{
\dontrun{

td <- file.path(tempdir(), "_my_first_project")

# define the work: a list of numbers
my_work <- as.list(1:10)

# define the processing function to work on one item
square_a_number <- function(x) {
  Sys.sleep(1)
  return(x^2)
}

# define the combine function for the list of results
sum_all_results <- function(results_list) {
  sum(unlist(results_list))
}

# run the workflow
final_sum <- tarflowr_run(
  work_units = my_work,
  process_func = square_a_number,
  combine_func = sum_all_results,
  project_dir = td,
  workers = 4
)

# final target value is 385
print(final_sum)

# now inspect "_my_first_project" folder to see the
# generated _targets.R file and the _targets/ cache

# rerun and get the result instantly from the cache:
cached_sum <- tarflowr_run(
  work_units = my_work,
  process_func = square_a_number,
  combine_func = sum_all_results,
  project_dir = td,
  workers = 4
)
print(cached_sum)

}
}
\author{
Andrew G. Brown
}
