---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# tarflowr

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![tarflowr Manual](https://img.shields.io/badge/docs-HTML-informational)](https://humus.rocks/tarflowr/)
<!-- badges: end -->

<img src = "https://i.imgur.com/vl0dkkc.png" alt = "tarflowr hexsticker" title = "tarflowr hexsticker" width = "40%" height = "40%" hspace="15" vspace="15" align="right"/>

> [!NOTE]
>
> This package is _experimental_. The internals are hacky and subject to change.
It is a proof of concept: kicking the tires on a system that can float above the
level of a single 'targets' pipeline. 

The goal of {tarflowr} (say: "tar flower") is to provide a simple, high-level
interface for creating and executing 'targets' pipelines, so users can focus
more on their specific analysis, not on pipeline orchestration.

The philosophy is based on the concept of arbitrary "work units." A {tarflowr}
workflow is a {targets} pipeline, but work units within that workflow can be
{targets} pipelines themselves: either generated by {tarflowr} or custom-made.
This abstraction allows one to develop and test each sub-project independently,
and then use {tarflowr} as an "orchestrator" to run and combine sub-projects at
scale.

The `tarflowr_run()` function serves as a high-level interface to the 'targets'
and 'crew' packages. It programmatically generates a `_targets.R` pipeline file
based on user-provided inputs, runs the pipeline, and returns the final result.
It is designed to abstract the complexity of setting up a 'targets'-based workflow
for common "map-reduce" or "split-apply-combine" tasks.

## Installation

You can install the development version of tarflowr like so:

``` r
if (!require("remotes")) install.packages("remotes")
remotes::install_github("brownag/tarflowr")
```

## Example

This is a basic example of calculating a sum of squares in parallel:

```{r example}
library(tarflowr)

PROJECT_DIR <- file.path(tempdir(), "_my_first_project")

# define the work: a list of numbers
my_work <- as.list(1:10)

# define the processing function to work on one item
square_a_number <- function(x) {
  Sys.sleep(1*1)
  return(x^2)
}

# define the combine function for the list of results
sum_all_results <- function(results_list) {
  sum(unlist(results_list))
}

# run the workflow
final_sum <- tarflowr_run(
  work_units = my_work,
  process_func = square_a_number,
  combine_func = sum_all_results,
  project_dir = PROJECT_DIR,
  workers = 4
)

# result is 385
final_sum

# see "_my_first_project" for _targets.R file and _targets/ cache.

# when re-run, we get the result from the cache:
cached_sum <- tarflowr_run(
  work_units = my_work,
  process_func = square_a_number,
  combine_func = sum_all_results,
  project_dir = PROJECT_DIR,
  workers = 4,
)
cached_sum
```

```{r, echo=FALSE}
unlink(file.path(tempdir(), "_my_first_project"), recursive = TRUE)
```
